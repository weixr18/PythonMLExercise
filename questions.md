# 机器学习编程问题

## 代码列表

题号 | 代码文件
:-:|:-:  
1| Linear_regression.py Quardratic_regression.py
2| Logistic_regression.py Fisher.py
3| Softmax_regression.py
4| MLP.py
5| SVM.py
6| KNN.py Conpressed_NN.py
7| Random_forest.py
8| Parameter_estimate.py
9| Non_param_estimate.py
10| HMM.py
11| Naive_bayes.py
12| Regular_linear_regression.py
13| Feature_selection.py
14| MDS.py
15| Feature_extraction.py
16| Cluster.py

## 题目汇总

### 1 线性回归练习

请对附件中的数据（prostate_train.txt 和 prostate_test.txt）使用前四个临床数据（即 lcavol，lweight，lbph，svi）对前列腺特异抗原水平（lpsa）进行预测。所给出的文件中，前 4 列每列代表一个临床数据（即特征），最后一列是测量的前列腺特异抗原水平（即预测目标的真实值）；每行代表一个样本。
作业要求：
（1） 在不考虑交叉项的情况下，利用 Linear Regression 对 prostate_train.txt 的数据进行回归，给出回归结果，并对 prostate_test.txt 文件中的患者进行预测，给出结果评价。
（2） 如果考虑交叉项，是否会有更好的预测结果？请给出你的理由。

### 2 线性分类器练习

请对附件中的数据（breast-cancer-wisconsin.txt，来自于 UCIML），使用罗杰斯特回归和 Fisher 线性判别设计分类器，实现良性和恶性乳腺癌的分类和预测，给出正确率并对这两种方法做出比较。
附件乳腺癌诊断数据集是699 × 11维的矩阵，11维的特征信息如下。

Attribute Domain  

1. Sample code number id number  
2. Clump Thickness 1 - 10  
3. Uniformity of Cell Size 1 - 10  
4. Uniformity of Cell Shape 1 - 10  
5. Marginal Adhesion 1 - 10  
6. Single Epithelial Cell Size 1 - 10  
7. Bare Nuclei 1 - 10  
8. Bland Chromatin 1 - 10  
9. Normal Nucleoli 1 - 10  
10. Mitoses 1 - 10  
11. Class: (0 for benign, 1 for malignant)  

要求：Logistic 回归可以调用函数，Fisher 线性判别请自行编写程序实现。

### 3 用 Softmax 回归进行人脸识别  

在课上我们已经学习了如何使用 Logistic Regression 进行二分类。请大家阅读 Softmax Regression 并回答以下问题。
（1） Softmax Regression 是线性还是非线性分类器？请说明你的理由（提示：可以从位于分界面上的点入手分析）。
（2） 在附件中我们给出了 10 个人的人脸图像（数据来自 VGGface2，附件为Pictures.rar）。请用 Softmax Regression 设计分类器，实现以下要求：
· 请随机取出 2 个人的图像，75%作为训练集，25%作为测试集，给出Softmax 的测试集正确率；同时，计算出 TPR, FPR, TNR, FNR, sensitivity, specificity, FDR；绘制 ROC 曲线，计算 AUC。  请随机取出 5 个人的图像，75%作为训练集，25%作为测试集，给出Softmax 的测试集正确率。
· 请使用所有人的图像，75%作为训练集，25%作为测试集，给出Softmax 的测试集正确率。
以上的测试中你的正确率是如何变化的？总结变化并给出合理解释。

### 4 用多层感知器进行人脸识别

在题目 3 中，我们 Softmax Regression 设计了人脸分类器，在本章中，请使用多层感知器进行同样的实验。讨论实验中多层感知器设计和训练中的因素对结果的影响，将本次实验结果与上次实验结果进行对比分析。

### 5 用 SVM 进行人脸识别

在题目 3 和题目 4 中，我们分别用 Softmax Regression 和多层感知器设计了人脸分类器，在本章中，请使用 SVM 进行同样的实验。讨论实验中核函数及其参数选择对结果的影响，将本次实验结果与之前的实验结果进行对比分析。

### 6 用 KNN 进行人脸识别

在之前的作业中，我们已经用 softmax regression、多层感知器以及 SVM 设计了人脸分类器，在本题中，请使用 KNN 进行同样的实验。并且请在十分类问题中，继续讨论以下问题：
（1） 探讨不同的 k 值对分类器性能的影响：分别取𝑘 = 1, 3, 5, 7, 9，观察测试正确率随 k 值的变化。 
（2） 探讨不同的距离度量方式对分类器性能的影响：选取你认为最优的 k 值，分别以欧氏距离、曼哈顿距离、切比雪夫距离、余弦距离作为距离度量，观察距离度量方式对测试正确率的影响。
（3） 【选做】自行编程实现压缩近邻法，选取你认为最优的 k 值与距离度量方式，比较压缩之后，KNN 算法在测试正确率、时空复杂度上的变化。

### 7 用随机森林进行人脸识别

请使用随机森林进行同样的人脸识别实验，并且在十分类问题中，继续讨论以下问题：
（1） 探讨树的数量对分类器性能的影响：改变随机森林中决策树的数量，观察并比较训练正确率与测试正确率的变化，说明产生这种现象的原因。
（2） 探讨树的最大深度对分类器性能的影响：选取你认为最优的决策树数量，调整参数限制随机森林中决策树的最大深度，观察测试正确率随决策树最大深度的变化。

### 8 最大似然估计与贝叶斯估计

现有样本数据集𝑿 = {𝑥1, 𝑥2, … , 𝑥𝑛}，我们假设其来自于正态分布𝑁(𝜇, 𝜎2)，请分别推导最大似然估计与贝叶斯估计（推导贝叶斯估计时假定方差已知）的模型参数，并完成以下问题：
（1） 请从标准正态分布𝑁(0,1)中分别抽取 10，100，1000 个样本数据作为𝑿，利用最大似然估计正态分布假设下的模型参数，分别重复三次实验，将同一抽样量下的三次重复实验估计的概率密度分布曲线绘制在一张图片内，并与标准正态分布的概率密度分布曲线比较。
（2） 假设均值𝜇满足正态先验𝑝(𝜇)~𝑁(−5, 𝜎02)，请利用（1）中样本容量为1000 的样本集𝑿，绘制出当𝜎02 = 0.01𝜎2, 0.1𝜎2, 𝜎2, 10𝜎2时贝叶斯估计的概率密度函数曲线，并与标准正态分布进行比较。
（3） 改从均匀分布𝑈(0,1)中抽取 100 个样本数据作为𝑿，正态分布的假设不变，重复（1）的实验，绘制出估计得到的概率密度分布曲线图，并与均匀分布𝑈(0,1)的概率密度分布曲线图比较。

### 9 非参数估计与贝叶斯决策

请生成 500 个样本数据，其中 250 个数据点采样于𝑁(−2.5, 1)，记为正样本；剩余 250 个数据采样于𝑁(2.5, 2)，记为负样本。随机取出 70%的数据作为训练集，30%的数据作为测试集，完成以下问题： 
（1） 利用 Parzen 窗的高斯核，使用训练集中的数据对正样本和负样本分别进行非参数估计。
（2） 利用（1）中非参数估计的概率密度，请使用最小错误率的贝叶斯决策对测试集样本进行预测，给出测试集的错误率。
（3） 利用（1）中非参数估计的概率密度，请使用最小风险的贝叶斯决策对测试集样本进行预测，惩罚矩阵如下：

真实值\预测值 | 正样本 | 负样本
:-:|:-:|:-:|:-:
正样本| 0| 10
负样本| 1| 0  

（4） 结合你的实验结果，简述最小风险准则与最小错误率准则有什么不同。

### 10 作弊骰子

一位赌场老板最近发现，一名玩家在掷骰子的游戏中总能取胜，他怀疑这
名玩家在游戏中将公平骰子偷换成了不公平的骰子，于是他用摄像头拍下了每局游戏骰子的点数，希望请你帮忙分析出这名玩家是否偷换了骰子以及该骰子出现各点的概率。
（1） 点数信息存于 sequences.npy 文件中，其中每一行是一局游戏，每一列是一次掷骰子出现的点数，文件中总共包括 200 局游戏，每局游戏各掷骰子 30 次，请据此建立并训练 HMM 模型，并在报告中给出拟合得到的初始、转移、发射概率。
（2） 根据你建立的模型，分别采用前向算法和后向算法手动计算序列“6、6 、6、6”出现的概率，比较两次计算的结果是否相同。
（3） 假如这名玩家正在游戏中，目前已经观察到本局游戏前 15 次出现的点数为：3、2、1、3、4、5、6、3、1、4、1、6、6、2、6，请你根据所建立的模型，推断该玩家是否正在作弊，如果是，是在何时偷换的骰子？
提示：
（1） HMM 模型的建立可以调用 python 中的 hmmlearn 模块，hmmlearn可直接通过 pip install hmmlearn 安装，具体使用方法请自行搜索。
（2） 友情提醒，赌博伤身，本题背景纯属虚构。

### 11 垃圾邮件分类

在本题中，我们将尝试建立朴素贝叶斯分类器对垃圾邮件进行分类。附件spambase.data 中共包含 4601 封邮件信息，该文件的前 57 列为邮件特征，最后1 列为分类标签，每一维特征的详细描述见 spambase.names 文件。请从所有样本中随机抽取 1000 封邮件作为测试集，用余下的样本作为训练集训练朴素贝叶斯分类器，并完成以下要求：
· 给出测试集正确率
· 绘制混淆矩阵，计算出 TPR、FPR、TNR、FNR
· 绘制 ROC 曲线，计算 AUC

### 12 线性回归、岭回归和 LASSO 回归

请编写代码生成以下仿真数据，探索线性回归、岭回归和 LASSO 回归模型对共线性问题的表现。
y = 3𝑥1 + 2 + 𝜀1, 𝑥1 = 1, … ,20
𝑥2 = 0.05𝑥1 + 𝜀2
𝜀1 ∈ N(0, 2), 𝜀2 ∈ N(0, 0.5)

若我们将与𝑥1有强相关关系的噪声𝑥2误认为是一维特征（即输入特征变为了[𝑥1, 𝑥2]），请同学们尝试使用上述三种模型对y进行回归，并回答以下问题。
(1) 请给出𝑥1, 𝑥2的相关系数。
(2) 请多次生成数据，观察正则化系数为 1 情况下三种模型拟合参数的稳定性。
(3) 针对于岭回归和 LASSO，调整正则化系数（调整范围不要过大，0~10 之间即可），你能发现什么?

### 13 特征选择

附件 feature_selection_X.txt 中给出了 400 个组织样本数据，每一行是一维样本，每一列代表一维特征，feature_selection_Y.txt 中给出了样本对应的标签（1 代表肿瘤组织，0 代表正常组织）。请随机抽取 300 个样本作为训练集，100 个样本作为测试集。使用特征选择算法，挑选出区分不同组织的特征，利用分类器进行分类：
(1) 分别用类内类间距离和最大信息系数(互信息的另一种度量方式)的判据选择1, 5, 10, 20, 50, 100 个特征，用 Logistic 回归进行分类，并比较与不做特征选择时候的模型预测效果；除此之外，请比较两种方法在这些特征个数时挑选出的特征子集有多少特征是相同的；
(2) 请简述前向算法的流程，使用前向算法进行特征选择,并使用 Logistic 回归作为分类器。并比较与（1）中选出特征的异同。
(3) 决策树算法在学习过程中会自动选择特征。请使用决策树对数据进行分类，并观察比较决策树中用到的特征与（1）和（2）中选出的特征的重合程度。

### 14 城市距离的 MDS 可视化

经典的 MDS（Multidimensional Scaling）方法起源于当我们仅能获取到物体之间的距离的时候，如何由此重构它的坐标。附件 city_dist.xlsx 中是 34 个城市之间的相对距离，请用 MDS 方法得到城市的二维表示并作图，简要分析你的可视化结果与真实地图上各个城市相对位置的差异。

### 15 MNIST 数据集的特征提取

在本题中，我们将数据集中的“0”和“8”两类样本集进行降维，并观察降维前后测试正确率的变化。
（1） 请分别用 PCA、ISOMAP、LLE、tSNE 算法将训练集的数据降到二维并可视化，每一类样本用不同颜色的点表示，说明你从可视化图中能观察到什么信息。
（2） 请用PCA算法将数据降维到1,10,20,50,100,300维，采用你认为合适的分类器分类，说明正确率随降维后维数的变化关系，并与不做降维之前的测试正确率进行比较。
（3） 请讨论对于分类问题，应该先做PCA降维再划分训练集、测试集进行学习；还是应该先划分训练集和测试集，再在训练集上做PCA。

### 16 MNIST 数据集聚类

在本问题中，我们将利用聚类算法对 MNIST 训练集的“0”，“1”，“2”三类样本集进行聚类分析，并观察各聚类算法的性能差异。
（1） 请利用 K-means 算法，在 1 到 10 的类别数下对样本集进行聚类，分别使 用误差平方和𝐽𝑒、标准化互信息 NMI 和轮廓系数 SC 确定聚类数目，并结合真实的类别数进行分析。 
（2） 请利用 K-means 算法对样本集进行聚类（类别数为 3），在算法中尝试三 种不同的初始化方法，并采用 NMI 评估你的聚类结果（多次运行取平均值），简述各初始化方法的特点。 
（3） 请利用分级聚类算法重复（2）的实验，在算法中尝试不同的类别距离和样本距离度量方式，采用 NMI 评估你的聚类结果，简述不同距离度量方式
的特点。
（4） 【选做】结合（2）、（3）中的聚类结果，编写一致聚类算法对样本重新聚类，采用 NMI 评估你的聚类结果，观察在此问题中，一致聚类算法是否对聚类效果有所提升。

